## Introduction
The goal for this notebook is to produce a submission file to participate in Kaggle Natural Language Processing with Disaster Tweets. https://www.kaggle.com/competitions/nlp-getting-started

## Dataset description:
The dataset consists on two files one file for training and another for testing. The training file contains 7613 tweets and the test file contains 3263 tweets.

## Problem description:
The problem is how to classify tweets into tweets that are related or not related to real life disasters.

## Approach:
Run a simple text data preprocessing (cleaning, tokenizing and making sequences/arrays) and use these arrays to train two models based on LSTM and GRU.
This notebook is designed to be run in Colab: https://colab.research.google.com/drive/1UuwSdIc8wCHrk_q6YRx5RUChn9_eohWe#scrollTo=oterf-EIE2kr
